import whisper
import sys
import os
import re
from typing import List, Dict, Tuple, Optional
import numpy as np
from moviepy.editor import (VideoFileClip, AudioFileClip, TextClip, ImageClip,
                            CompositeVideoClip, CompositeAudioClip, concatenate_videoclips,
                            ColorClip)
import moviepy.video.fx.all as vfx
from moviepy.config import change_settings

# ==========================================
# [ì„¤ì • ì˜ì—­] í™˜ê²½ì— ë§ê²Œ ìˆ˜ì •
# ==========================================
change_settings({"IMAGEMAGICK_BINARY": "/opt/homebrew/bin/magick"}) # ë§¥ë¶ ê²½ë¡œ
FONT_PATH = "/Users/lux/Library/Fonts/SUIT-Bold.otf" 

# íŒŒì¼ ì„¤ì •
DEFAULT_AUDIO_PATH = "download.wav"
VIDEO_FOLDER = "vd"  # ë¹„ë””ì˜¤ íŒŒì¼ì´ ìˆëŠ” í´ë”
BGM_PATH = "bg.mp3"  # ë°°ê²½ìŒì•… íŒŒì¼ (ì„ íƒì‚¬í•­)
BGM_VOLUME = 0.15    # ë°°ê²½ìŒì•… ë³¼ë¥¨ (0.0 ~ 1.0, ë‚®ì„ìˆ˜ë¡ ì‘ìŒ)

# í™”ë©´ ë° ìë§‰ ì„¤ì •
TARGET_SIZE = (1080, 1920) # ìˆì¸  í•´ìƒë„
FONT_SIZE = 65
MAX_LINE_CHARS = 20 # í•œ ì¤„ ìµœëŒ€ ê¸€ììˆ˜(ë‹¨ì–´ ë‹¨ìœ„ í‘œì‹œ)
TRANSITION_DURATION = 0.0 # í•˜ë“œ ì»· (ì†ë„ ë§ì¶¤ì´ë¼ ëŠê¹€ ì—†ì´ ì—°ê²°ë¨)
MIN_SPEED = 0.8  # ë„ˆë¬´ ëŠë¦¬ë©´ ë¶€ìì—°ìŠ¤ëŸ¬ì›€
MAX_SPEED = 1.3  # ë„ˆë¬´ ë¹ ë¥´ë©´ ë¶€ìì—°ìŠ¤ëŸ¬ì›€
SUBTITLE_PAD = 0.0  # ìë§‰ ì—¬ìœ  ì‹œê°„ (ê²¹ì¹¨ ë°©ì§€)
# ==========================================

def fit_video_to_audio(video_path, target_duration):
    """
    ì˜ìƒì„ ì˜¤ë””ì˜¤ ê¸¸ì´(target_duration)ì— ê°•ì œë¡œ ë§ì¶”ëŠ” í•¨ìˆ˜.
    ê¸¸ë©´ ë°°ì†(Fast), ì§§ìœ¼ë©´ ìŠ¬ë¡œìš°(Slow)ë¥¼ ì ìš©í•¨ (CapCut ë°©ì‹).
    """
    clip = VideoFileClip(video_path)
    
    # 1. í™”ë©´ ê½‰ ì°¨ê²Œ ë¦¬ì‚¬ì´ì¦ˆ (Center Crop)
    # í˜„ì¬ ì˜ìƒ ë¹„ìœ¨(9:16)ì´ ë§ì§€ë§Œ, í•´ìƒë„ê°€ ë‚®ìœ¼ë¯€ë¡œ(416x752) 1080x1920ìœ¼ë¡œ ëŠ˜ë¦¼
    ratio_w = TARGET_SIZE[0] / clip.w
    ratio_h = TARGET_SIZE[1] / clip.h
    scale_factor = max(ratio_w, ratio_h)
    
    clip = clip.resize(scale_factor)
    clip = clip.crop(x_center=clip.w/2, y_center=clip.h/2, 
                     width=TARGET_SIZE[0], height=TARGET_SIZE[1])
    
    # 2. ì†ë„ ì¡°ì ˆ (Speed Ramping)
    # ëª©í‘œ ì‹œê°„ë³´ë‹¤ ì˜ìƒì´ ê¸¸ë©´ ì†ë„ë¥¼ ë†’ì´ê³ (>1.0), ì§§ìœ¼ë©´ ì†ë„ë¥¼ ë‚®ì¶¤(<1.0)
    original_duration = clip.duration
    target_duration = max(0.05, target_duration)
    speed_factor = original_duration / target_duration

    # ë„ˆë¬´ í° ë°°ì†ì€ ì»· í¸ì§‘ìœ¼ë¡œ ì™„í™”
    if speed_factor > MAX_SPEED:
        # í•„ìš”í•œ ê¸¸ì´ ê³„ì‚° (MAX_SPEED ë°°ì†ìœ¼ë¡œ ì¬ìƒí–ˆì„ ë•Œ target_durationì´ ë˜ëŠ” ê¸¸ì´)
        needed_len = target_duration * MAX_SPEED
        needed_len = min(needed_len, original_duration)
        
        # ì˜ìƒì˜ ì•ë¶€ë¶„ 20% ì œì™¸í•˜ê³  ì¤‘ê°„~ë ë¶€ë¶„ ì‚¬ìš© (ì•ˆì •ì ì¸ êµ¬ê°„)
        safe_start = original_duration * 0.2
        available_len = original_duration - safe_start
        
        if available_len >= needed_len:
            # ì¤‘ê°„ ë¶€ë¶„ ì‚¬ìš©
            start_at = safe_start + (available_len - needed_len) / 2
        else:
            # ê¸¸ì´ê°€ ë¶€ì¡±í•˜ë©´ ì•ë¶€ë¶„ë¶€í„° ì‚¬ìš©
            start_at = max(0.0, (original_duration - needed_len) / 2)
        
        clip = clip.subclip(start_at, start_at + needed_len)
        original_duration = clip.duration
        speed_factor = original_duration / target_duration

    # ë„ˆë¬´ ëŠë¦° ë°°ì†ì€ í—ˆìš©ì¹˜ê¹Œì§€ë§Œ ë‚®ì¶”ê³  ë‚˜ë¨¸ì§€ëŠ” í”„ë ˆì„ ë™ê²°ë¡œ ì²˜ë¦¬
    if speed_factor < MIN_SPEED:
        speed_factor = MIN_SPEED

    print(f"   âš™ï¸ ì†ë„ ì¡°ì •: {original_duration:.2f}ì´ˆ -> {target_duration:.2f}ì´ˆ (ë°°ì†: {speed_factor:.2f}x)")

    # moviepy vfx.speedx ì ìš©
    final_clip = clip.fx(vfx.speedx, speed_factor)

    # ë¶€ì¡±í•œ ê¸¸ì´ëŠ” ë§ˆì§€ë§‰ í”„ë ˆì„ìœ¼ë¡œ ì±„ì›€ (ë£¨í”„ ë°©ì§€)
    if final_clip.duration < target_duration:
        pad = target_duration - final_clip.duration
        t_final = max(0.0, final_clip.duration - 0.03)
        t_orig = max(0.0, clip.duration - 0.03)
        try:
            frame = final_clip.get_frame(t_final)
        except Exception:
            try:
                frame = clip.get_frame(t_orig)
            except Exception:
                # ìµœí›„ì˜ ìˆ˜ë‹¨: ê²€ì • í™”ë©´ìœ¼ë¡œ íŒ¨ë”©
                frame = np.zeros((TARGET_SIZE[1], TARGET_SIZE[0], 3), dtype=np.uint8)
        freeze_clip = ImageClip(frame).set_duration(pad)
        final_clip = concatenate_videoclips([final_clip, freeze_clip])

    # ë¯¸ì„¸í•œ ì˜¤ì°¨ ì œê±°ë¥¼ ìœ„í•´ duration ê°•ì œ ê³ ì •
    final_clip = final_clip.set_duration(target_duration)

    return final_clip

def create_subtitle(text, duration):
    """ìë§‰ë°” ìƒì„± (ë‹¨ì¼ ë¼ì¸)"""
    txt_clip = TextClip(text, fontsize=FONT_SIZE, color='white',
                        font=FONT_PATH, method='label', align='center', kerning=-1)
    
    # ë°°ê²½ ë°•ìŠ¤ (ê²€ì • ë°˜íˆ¬ëª…)
    bg_w = txt_clip.w + 60
    bg_h = txt_clip.h + 40
    bg_clip = ColorClip(size=(bg_w, bg_h), color=(0,0,0)).set_opacity(1)
    
    # í•©ì„± ë° ìœ„ì¹˜ ì§€ì •
    sub_final = CompositeVideoClip([bg_clip, txt_clip.set_pos('center')])
    sub_final = sub_final.set_duration(duration).set_pos(('center', 1300)) # í™”ë©´ í•˜ë‹¨
    return sub_final

def normalize_word(word: str) -> str:
    word = word.strip().lower()
    return re.sub(r"[^0-9a-zê°€-í£]+", "", word)

def split_display_words(text: str) -> List[str]:
    return [w for w in re.split(r"\s+", text.strip()) if w]

def extract_whisper_words(segments: List[Dict]) -> List[Dict]:
    words = []
    for seg in segments:
        if 'words' in seg and seg['words']:
            for w in seg['words']:
                word = normalize_word(w.get('word', ''))
                if not word:
                    continue
                words.append({
                    "word": word,
                    "start": w.get('start', seg['start']),
                    "end": w.get('end', seg['end'])
                })
    return words

def align_script_lines(script_lines: List[str], whisper_words: List[Dict]) -> List[Dict]:
    pointer = 0
    aligned = []
    
    for line_idx, line in enumerate(script_lines):
        display_words = split_display_words(line)
        normalized_words = [normalize_word(w) for w in display_words]
        word_times: List[Optional[Tuple[float, float]]] = [None] * len(display_words)
        line_start = None
        line_end = None
        matched_count = 0

        for i, nw in enumerate(normalized_words):
            if not nw:
                continue
            
            # í˜„ì¬ ìœ„ì¹˜ì—ì„œ ì•ë’¤ 5ê°œ ë‹¨ì–´ ë²”ìœ„ ë‚´ì—ì„œ fuzzy ë§¤ì¹­
            best_match_idx = None
            search_start = max(0, pointer - 2)
            search_end = min(len(whisper_words), pointer + 10)
            
            for j in range(search_start, search_end):
                if whisper_words[j]["word"] == nw:
                    best_match_idx = j
                    break
            
            if best_match_idx is not None:
                w = whisper_words[best_match_idx]
                word_times[i] = (w["start"], w["end"])
                if line_start is None:
                    line_start = w["start"]
                line_end = w["end"]
                pointer = best_match_idx + 1
                matched_count += 1
            else:
                # ë§¤ì¹­ ì‹¤íŒ¨ ì‹œ ë¶€ë¶„ ë¬¸ìì—´ë¡œ ì¬ì‹œë„
                for j in range(search_start, search_end):
                    ww = whisper_words[j]["word"]
                    # 3ê¸€ì ì´ìƒì´ê³  ë¶€ë¶„ ì¼ì¹˜í•˜ë©´ ë§¤ì¹­
                    if len(nw) >= 3 and (nw in ww or ww in nw):
                        w = whisper_words[j]
                        word_times[i] = (w["start"], w["end"])
                        if line_start is None:
                            line_start = w["start"]
                        line_end = w["end"]
                        pointer = j + 1
                        matched_count += 1
                        break

        aligned.append({
            "text": line,
            "display_words": display_words,
            "word_times": word_times,
            "start": line_start,
            "end": line_end,
            "matched_words": matched_count
        })
    
    return aligned

def resolve_line_timings(aligned: List[Dict], segments: List[Dict], audio_duration: float) -> List[Dict]:
    # word ê¸°ë°˜ íƒ€ì´ë°ì´ ìˆìœ¼ë©´ ì ˆëŒ€ ë®ì–´ì“°ì§€ ì•ŠìŒ!
    # ì—†ëŠ” ê²½ìš°ì—ë§Œ ë³´ì™„
    for i, info in enumerate(aligned):
        if info["start"] is None or info["end"] is None:
            # word íƒ€ì„ìŠ¤íƒ¬í”„ê°€ ì™„ì „íˆ ì—†ëŠ” ê²½ìš°ë§Œ ì„¸ê·¸ë¨¼íŠ¸/ê· ë“±ë¶„í•  ì‚¬ìš©
            if i < len(segments):
                if info["start"] is None:
                    info["start"] = segments[i]["start"]
                if info["end"] is None:
                    info["end"] = segments[i]["end"]
            else:
                per = audio_duration / max(1, len(aligned))
                if info["start"] is None:
                    info["start"] = i * per
                if info["end"] is None:
                    info["end"] = min(audio_duration, (i + 1) * per)

    # ì‹œê°„ ê²€ì¦ ë° ìµœì†Œí•œì˜ ë³´ì •ë§Œ ìˆ˜í–‰
    for i, info in enumerate(aligned):
        start = info["start"]
        end = info["end"]
        
        # ìŒìˆ˜ duration ë°©ì§€
        if end <= start:
            end = start + 0.5
        
        info["start"], info["end"] = start, end

    # ë¼ì¸ ê°„ ê°„ê²© ì¶”ê°€ (ìì—°ìŠ¤ëŸ¬ìš´ íœ´ì‹)
    for i in range(len(aligned) - 1):
        current_end = aligned[i]["end"]
        next_start = aligned[i + 1]["start"]
        
        # ê°„ê²©ì´ ë„ˆë¬´ ì‘ìœ¼ë©´ ìµœì†Œ ê°„ê²© í™•ë³´
        if next_start - current_end < 0.2:
            gap = (next_start + current_end) / 2
            aligned[i]["end"] = gap - 0.1
            aligned[i + 1]["start"] = gap + 0.1

    # ë§ˆì§€ë§‰ ë¼ì¸ì€ ì˜¤ë””ì˜¤ ëê¹Œì§€
    if aligned:
        aligned[-1]["end"] = max(aligned[-1]["end"], audio_duration)
    
    return aligned

def chunk_words_with_times(info: Dict, max_chars: int) -> List[Dict]:
    words = info["display_words"]
    word_times = info["word_times"]
    line_start = info["start"]
    line_end = info["end"]
    duration = max(0.01, line_end - line_start)
    total_words = max(1, len(words))

    # 1. ë§¤ì¹­ë˜ì§€ ì•Šì€ ë‹¨ì–´ì˜ íƒ€ì´ë° ë³´ê°„
    interpolated_times = list(word_times)  # ë³µì‚¬
    
    # ì—°ì†ëœ ë¯¸ë§¤ì¹­ êµ¬ê°„ì„ ì°¾ì•„ì„œ ë³´ê°„
    i = 0
    while i < len(interpolated_times):
        if interpolated_times[i] is None:
            # ë¯¸ë§¤ì¹­ êµ¬ê°„ ì‹œì‘
            start_idx = i
            while i < len(interpolated_times) and interpolated_times[i] is None:
                i += 1
            end_idx = i
            
            # ì•ë’¤ ì‹œê°„ ì°¾ê¸°
            prev_time = None
            next_time = None
            
            if start_idx > 0 and interpolated_times[start_idx - 1] is not None:
                prev_time = interpolated_times[start_idx - 1][1]  # ì´ì „ ë‹¨ì–´ ë
            else:
                prev_time = line_start
            
            if end_idx < len(interpolated_times) and interpolated_times[end_idx] is not None:
                next_time = interpolated_times[end_idx][0]  # ë‹¤ìŒ ë‹¨ì–´ ì‹œì‘
            else:
                # ë‹¤ìŒ ë§¤ì¹­ ë‹¨ì–´ê°€ ì—†ìœ¼ë©´ ë¼ì¸ ëê¹Œì§€
                remaining = end_idx - start_idx
                next_time = prev_time + remaining * (duration / total_words)
            
            # ê· ë“± ë¶„ë°°
            gap = next_time - prev_time
            num_words = end_idx - start_idx
            word_duration = gap / num_words
            
            for j in range(start_idx, end_idx):
                offset = j - start_idx
                start = prev_time + offset * word_duration
                end = start + word_duration
                interpolated_times[j] = (start, end)
        else:
            i += 1

    # 2. Chunk ìƒì„± - TTS pause ê¸°ë°˜ìœ¼ë¡œ ìì—°ìŠ¤ëŸ½ê²Œ ë¶„í• 
    chunks = []
    current = []
    current_len = 0
    
    for idx, w in enumerate(words):
        if not current:
            current = [(idx, w)]
            current_len = len(w)
        else:
            # ì´ì „ ë‹¨ì–´ì™€ í˜„ì¬ ë‹¨ì–´ ì‚¬ì´ì˜ pause ì²´í¬
            prev_idx = current[-1][0]
            pause = 0.0
            
            if interpolated_times[idx] and interpolated_times[prev_idx]:
                # ì´ì „ ë‹¨ì–´ ë ì‹œê°„ê³¼ í˜„ì¬ ë‹¨ì–´ ì‹œì‘ ì‹œê°„ì˜ ì°¨ì´
                pause = interpolated_times[idx][0] - interpolated_times[prev_idx][1]
            
            # ìì—°ìŠ¤ëŸ¬ìš´ pause(0.2ì´ˆ ì´ìƒ) ë˜ëŠ” ìµœëŒ€ ê¸¸ì´ ì´ˆê³¼ ì‹œ chunk ë¶„í• 
            should_split = False
            
            if pause > 0.2:  # TTSì—ì„œ ê¸´ pauseê°€ ìˆëŠ” ì§€ì 
                should_split = True
            elif current_len + 1 + len(w) > max_chars:  # ê¸¸ì´ ì´ˆê³¼
                should_split = True
            
            if should_split:
                chunks.append(current)
                current = [(idx, w)]
                current_len = len(w)
            else:
                current.append((idx, w))
                current_len += 1 + len(w)
    
    if current:
        chunks.append(current)

    # 3. Chunk íƒ€ì´ë° ê³„ì‚° (TTS pause ê¸°ë°˜ ìì—°ìŠ¤ëŸ¬ìš´ ë¶„í• )
    out = []
    
    for chunk_idx, group in enumerate(chunks):
        idxs = [i for i, _ in group]
        chunk_text = " ".join([w for _, w in group])
        
        # pause ì •ë³´ ì €ì¥ (ë””ë²„ê¹…ìš©)
        pause_before = 0.0
        if chunk_idx > 0 and len(chunks[chunk_idx - 1]) > 0:
            prev_last_idx = chunks[chunk_idx - 1][-1][0]
            curr_first_idx = idxs[0]
            if interpolated_times[curr_first_idx] and interpolated_times[prev_last_idx]:
                pause_before = interpolated_times[curr_first_idx][0] - interpolated_times[prev_last_idx][1]
        
        # ë³´ê°„ëœ íƒ€ì´ë° ì‚¬ìš©
        times = [interpolated_times[i] for i in idxs]
        chunk_start = min(t[0] for t in times)
        chunk_end = max(t[1] for t in times)
        
        # ë¼ì¸ ë²”ìœ„ ë‚´ë¡œ ì œí•œ
        chunk_start = max(line_start, chunk_start)
        chunk_end = min(line_end, chunk_end)
        
        # ìµœì†Œ duration ë³´ì¥ (0.3ì´ˆ)
        min_duration = 0.3
        if chunk_end - chunk_start < min_duration:
            # ì¤‘ê°„ ì§€ì  ê¸°ì¤€ìœ¼ë¡œ í™•ì¥
            mid = (chunk_start + chunk_end) / 2
            chunk_start = max(line_start, mid - min_duration / 2)
            chunk_end = min(line_end, mid + min_duration / 2)
            
            # ì—¬ì „íˆ ì§§ìœ¼ë©´ ëê¹Œì§€ í™•ì¥
            if chunk_end - chunk_start < min_duration:
                chunk_end = min(line_end, chunk_start + min_duration)

        out.append({
            "text": chunk_text,
            "start": chunk_start,
            "end": chunk_end
        })
    
    # 4. Chunk ê°„ ê°„ê²© ì™„ì „ ì œê±° (ê¹œë¹¡ê±°ë¦¼ ì œê±°)
    for i in range(len(out) - 1):
        current_chunk = out[i]
        next_chunk = out[i + 1]
        
        gap = next_chunk["start"] - current_chunk["end"]
        
        if gap > 0.01:
            # ê°„ê²©ì´ ìˆìœ¼ë©´ í˜„ì¬ chunkë¥¼ ë‹¤ìŒ chunk ì‹œì‘ê¹Œì§€ ì—°ì¥
            out[i]["end"] = next_chunk["start"]
        elif gap < -0.01:
            # ê²¹ì¹˜ë©´ í˜„ì¬ chunkë¥¼ ë‹¤ìŒ chunk ì‹œì‘ ì§ì „ê¹Œì§€ë¡œ ì¡°ì •
            out[i]["end"] = next_chunk["start"]
    
    return out

# ==========================================
# ë©”ì¸ ì‹¤í–‰
# ==========================================
def load_video_files(folder_path):
    """ë¹„ë””ì˜¤ í´ë”ì—ì„œ ìˆœì°¨ì ìœ¼ë¡œ ë¹„ë””ì˜¤ íŒŒì¼ ë¡œë“œ"""
    if not os.path.exists(folder_path):
        print(f"\nğŸ“ '{folder_path}' í´ë”ê°€ ì—†ìŠµë‹ˆë‹¤. ìë™ìœ¼ë¡œ ìƒì„±í•©ë‹ˆë‹¤...")
        try:
            os.makedirs(folder_path)
            print(f"âœ… '{folder_path}' í´ë”ê°€ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.")
            print(f"   ì´ í´ë”ì— 1.mp4, 2.mp4, 3.mp4... í˜•ì‹ìœ¼ë¡œ ë¹„ë””ì˜¤ íŒŒì¼ì„ ë„£ì–´ì£¼ì„¸ìš”.")
        except Exception as e:
            print(f"â›”ï¸ í´ë” ìƒì„± ì‹¤íŒ¨: {e}")
        return []
    
    # ë¹„ë””ì˜¤ í™•ì¥ì
    video_extensions = ['.mp4', '.avi', '.mov', '.mkv', '.webm', '.flv']
    
    # í´ë” ë‚´ ëª¨ë“  íŒŒì¼ ê°€ì ¸ì˜¤ê¸°
    all_files = []
    for file in os.listdir(folder_path):
        file_path = os.path.join(folder_path, file)
        if os.path.isfile(file_path):
            ext = os.path.splitext(file)[1].lower()
            if ext in video_extensions:
                all_files.append((file, file_path))
    
    # íŒŒì¼ëª… ê¸°ì¤€ ì •ë ¬ (1.mp4, 2.mp4, ... ìˆœì„œ)
    try:
        all_files.sort(key=lambda x: int(os.path.splitext(x[0])[0]))
    except ValueError:
        # ìˆ«ìë¡œ ì •ë ¬ ë¶ˆê°€ëŠ¥í•˜ë©´ ì•ŒíŒŒë²³ ìˆœ
        all_files.sort()
    
    return [path for name, path in all_files]

def input_multiline_script():
    """ì—¬ëŸ¬ ì¤„ ëŒ€ë³¸ ì…ë ¥ë°›ê¸°"""
    print("\nğŸ“ ëŒ€ë³¸ ì…ë ¥")
    print("=" * 50)
    print("ì—¬ëŸ¬ ì¤„ì˜ ëŒ€ë³¸ì„ ì…ë ¥í•˜ì„¸ìš”.")
    print("ê° ì¤„ì´ í•˜ë‚˜ì˜ ì¥ë©´ì´ ë©ë‹ˆë‹¤.")
    print("ì…ë ¥ ì™„ë£Œ í›„ ë¹ˆ ì¤„ì—ì„œ Enterë¥¼ ëˆ„ë¥´ì„¸ìš”.")
    print("=" * 50)
    
    lines = []
    line_num = 1
    
    while True:
        try:
            line = input(f"[{line_num}] ")
            if line.strip() == "":
                if lines:  # ì´ë¯¸ ì…ë ¥ëœ ë‚´ìš©ì´ ìˆìœ¼ë©´ ì¢…ë£Œ
                    break
                else:  # ì²« ì¤„ì´ ë¹ˆ ì¤„ì´ë©´ ê³„ì†
                    continue
            lines.append(line.strip())
            line_num += 1
        except EOFError:
            break
    
    return lines

if __name__ == "__main__":
    print("ğŸš€ ì‡¼ì¸  ì˜ìƒ ìë™ ìƒì„± ì‹œì‘")
    print("=" * 50)
    
    # 1. ì˜¤ë””ì˜¤ íŒŒì¼ í™•ì¸
    print(f"\nğŸµ ì˜¤ë””ì˜¤ íŒŒì¼ ê²½ë¡œ (ê¸°ë³¸ê°’: {DEFAULT_AUDIO_PATH})")
    audio_input = input(f"Enterë¥¼ ëˆ„ë¥´ë©´ ê¸°ë³¸ê°’ ì‚¬ìš©, ë˜ëŠ” íŒŒì¼ ê²½ë¡œ ì…ë ¥: ").strip()
    AUDIO_PATH = audio_input if audio_input else DEFAULT_AUDIO_PATH
    
    if not os.path.exists(AUDIO_PATH):
        print(f"\nâ›”ï¸ ì˜¤ë¥˜: ì˜¤ë””ì˜¤ íŒŒì¼ '{AUDIO_PATH}'ì„(ë¥¼) ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤!")
        sys.exit(1)
    
    print(f"âœ… ì˜¤ë””ì˜¤ íŒŒì¼: {AUDIO_PATH}")
    
    # 1-1. ë°°ê²½ìŒì•… ì„¤ì •
    if os.path.exists(BGM_PATH):
        print(f"\nğŸ¶ ë°°ê²½ìŒì•… ë°œê²¬: {BGM_PATH}")
        bgm_choice = input(f"ë°°ê²½ìŒì•…ì„ ì¶”ê°€í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/n, ê¸°ë³¸ê°’: y): ").strip().lower()
        
        if bgm_choice == 'n':
            BGM_PATH = None
            print("   â„¹ï¸ ë°°ê²½ìŒì•… ì—†ì´ ì§„í–‰í•©ë‹ˆë‹¤")
        else:
            volume_input = input(f"BGM ë³¼ë¥¨ ì„¤ì • (0.0~1.0, ê¸°ë³¸ê°’: {BGM_VOLUME}): ").strip()
            if volume_input:
                try:
                    BGM_VOLUME = float(volume_input)
                    BGM_VOLUME = max(0.0, min(1.0, BGM_VOLUME))  # 0~1 ë²”ìœ„ë¡œ ì œí•œ
                    print(f"   âœ… BGM ë³¼ë¥¨: {BGM_VOLUME * 100:.0f}%")
                except ValueError:
                    print(f"   âš ï¸ ì˜ëª»ëœ ì…ë ¥. ê¸°ë³¸ê°’({BGM_VOLUME})ì„ ì‚¬ìš©í•©ë‹ˆë‹¤")
            else:
                print(f"   âœ… BGM ë³¼ë¥¨: {BGM_VOLUME * 100:.0f}% (ê¸°ë³¸ê°’)")
    else:
        print(f"\nğŸ¶ ë°°ê²½ìŒì•… íŒŒì¼ ì—†ìŒ ({BGM_PATH})")
        print("   â„¹ï¸ TTS ìŒì„±ë§Œ ì‚¬ìš©í•©ë‹ˆë‹¤")
        BGM_PATH = None
    
    # 2. ëŒ€ë³¸ ì…ë ¥
    USER_SCRIPT = input_multiline_script()
    
    if not USER_SCRIPT:
        print("\nâ›”ï¸ ì˜¤ë¥˜: ëŒ€ë³¸ì´ ì…ë ¥ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤!")
        sys.exit(1)
    
    print(f"\nâœ… {len(USER_SCRIPT)}ê°œ ë¼ì¸ ì…ë ¥ ì™„ë£Œ")
    for i, line in enumerate(USER_SCRIPT, 1):
        print(f"   [{i}] {line[:50]}{'...' if len(line) > 50 else ''}")
    
    # 3. ë¹„ë””ì˜¤ íŒŒì¼ ë¡œë“œ
    print(f"\nğŸ“‚ '{VIDEO_FOLDER}' í´ë”ì—ì„œ ë¹„ë””ì˜¤ íŒŒì¼ ê²€ìƒ‰ ì¤‘...")
    VIDEO_FILES = load_video_files(VIDEO_FOLDER)
    
    if not VIDEO_FILES:
        print("\nâ›”ï¸ ì˜¤ë¥˜: ë¹„ë””ì˜¤ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤!")
        print(f"   '{VIDEO_FOLDER}' í´ë”ì— 1.mp4, 2.mp4, 3.mp4... í˜•ì‹ìœ¼ë¡œ ë¹„ë””ì˜¤ íŒŒì¼ì„ ë„£ì–´ì£¼ì„¸ìš”.")
        sys.exit(1)
    
    print(f"\nâœ… {len(VIDEO_FILES)}ê°œ ë¹„ë””ì˜¤ íŒŒì¼ ë°œê²¬:")
    for i, video_file in enumerate(VIDEO_FILES, 1):
        filename = os.path.basename(video_file)
        print(f"   [{i}] {filename}")
    
    # 4. ëŒ€ë³¸ê³¼ ë¹„ë””ì˜¤ ìˆ˜ í™•ì¸
    if len(USER_SCRIPT) != len(VIDEO_FILES):
        print(f"\nâš ï¸ ê²½ê³ : ëŒ€ë³¸ ìˆ˜({len(USER_SCRIPT)})ì™€ ì˜ìƒ ìˆ˜({len(VIDEO_FILES)})ê°€ ì¼ì¹˜í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤!")
        if len(USER_SCRIPT) > len(VIDEO_FILES):
            print(f"   ì˜ìƒì´ {len(USER_SCRIPT) - len(VIDEO_FILES)}ê°œ ë¶€ì¡±í•©ë‹ˆë‹¤. ë§ˆì§€ë§‰ ì˜ìƒì´ ì¬ì‚¬ìš©ë©ë‹ˆë‹¤.")
        else:
            print(f"   ì˜ìƒì´ {len(VIDEO_FILES) - len(USER_SCRIPT)}ê°œ ì´ˆê³¼ì…ë‹ˆë‹¤. ì¼ë¶€ ì˜ìƒì€ ì‚¬ìš©ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
    else:
        print(f"\nâœ… ëŒ€ë³¸ê³¼ ì˜ìƒ ìˆ˜ê°€ ì¼ì¹˜í•©ë‹ˆë‹¤!")
    
    # 5. ì‹œì‘ í™•ì¸
    print("\n" + "=" * 50)
    print("ğŸ“‹ ì„¤ì • ìš”ì•½:")
    print(f"   ğŸµ ì˜¤ë””ì˜¤: {AUDIO_PATH}")
    if BGM_PATH and os.path.exists(BGM_PATH):
        print(f"   ğŸ¶ ë°°ê²½ìŒì•…: {BGM_PATH} (ë³¼ë¥¨: {BGM_VOLUME * 100:.0f}%)")
    else:
        print(f"   ğŸ¶ ë°°ê²½ìŒì•…: ì—†ìŒ")
    print(f"   ğŸ“ ëŒ€ë³¸: {len(USER_SCRIPT)}ì¤„")
    print(f"   ğŸ¬ ì˜ìƒ: {len(VIDEO_FILES)}ê°œ")
    print("=" * 50)
    
    response = input("\nì˜ìƒ ìƒì„±ì„ ì‹œì‘í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/n): ").strip().lower()
    if response != 'y':
        print("ì‘ì—…ì´ ì·¨ì†Œë˜ì—ˆìŠµë‹ˆë‹¤.")
        sys.exit(0)
    
    print("\nğŸ¬ ì˜ìƒ ìƒì„± ì‹œì‘...")

    # 1. Whisperë¡œ ì˜¤ë””ì˜¤ ë¶„ì„ (ì‹œê°„ ì •ë³´ íšë“)
    # User Scriptê°€ ìˆìœ¼ë¯€ë¡œ, WhisperëŠ” 'ì‹œê°„(Timestamp)' ì¶”ì¶œìš©ìœ¼ë¡œë§Œ ì‚¬ìš©í•©ë‹ˆë‹¤.
    model = whisper.load_model("base")
    try:
        result = model.transcribe(AUDIO_PATH, language='ko', word_timestamps=True)
    except TypeError:
        result = model.transcribe(AUDIO_PATH, language='ko')
    segments = result['segments']
    whisper_words = extract_whisper_words(segments)
    
    final_clips = []
    original_audio = AudioFileClip(AUDIO_PATH)
    audio_duration = original_audio.duration
    
    print(f"\nğŸ“Š ë¶„ì„ ê²°ê³¼:")
    print(f"   ğŸ“‹ ëŒ€ë³¸ ë¼ì¸ ìˆ˜: {len(USER_SCRIPT)}")
    print(f"   ğŸ™ Whisper ì¸ì‹ ë¬¸ì¥ ìˆ˜: {len(segments)}")
    print(f"   ğŸ”¤ Whisper ë‹¨ì–´ ìˆ˜: {len(whisper_words)}")
    print(f"   ğŸ¬ ì˜ìƒ íŒŒì¼ ìˆ˜: {len(VIDEO_FILES)}")
    
    if len(whisper_words) == 0:
        print("âš ï¸ Whisperì—ì„œ ë‹¨ì–´ íƒ€ì„ìŠ¤íƒ¬í”„ë¥¼ ì¶”ì¶œí•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ë¬¸ì¥ ë‹¨ìœ„ íƒ€ì´ë°ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.")
    else:
        print("\nğŸ” Whisper ì„¸ê·¸ë¨¼íŠ¸ ìƒì„¸:")
        for i, seg in enumerate(segments):
            print(f"   [{i+1}] {seg['start']:.2f}~{seg['end']:.2f}s: {seg['text']}")
    
    loop_count = len(USER_SCRIPT)
    aligned = align_script_lines(USER_SCRIPT, whisper_words)
    aligned = resolve_line_timings(aligned, segments, audio_duration)
    
    # ë””ë²„ê·¸: íƒ€ì´ë° í™•ì¸
    print("\nâ° ë¼ì¸ë³„ íƒ€ì´ë° ì •ë³´ (word ë§¤ì¹­ í›„):")
    for i, info in enumerate(aligned):
        if info["start"] is not None and info["end"] is not None:
            duration = info["end"] - info["start"]
            start_str = f"{info['start']:.2f}"
            end_str = f"{info['end']:.2f}"
        else:
            duration = 0
            start_str = "N/A"
            end_str = "N/A"
        matched = info.get("matched_words", 0)
        total = len(info["word_times"])
        print(f"   [{i+1}] {duration:.2f}ì´ˆ ({start_str} ~ {end_str}): {info['text'][:40]}... [ë§¤ì¹­: {matched}/{total}]")
    
    # ì „ì²´ ë¹„ë””ì˜¤ í´ë¦½ ìƒì„± - ë‹¤ìŒ ë¼ì¸ ì‹œì‘ ì§ì „ê¹Œì§€ ì—°ì¥ (ìë§‰ê³¼ ë™ì¼í•œ ë¡œì§)
    print("\nğŸ¬ ì˜ìƒ í´ë¦½ íƒ€ì´ë° ì¡°ì •:")
    
    # 1ë‹¨ê³„: ê° ë¼ì¸ì˜ ì‹¤ì œ ì˜ìƒ duration ê³„ì‚° (ë‹¤ìŒ ë¼ì¸ ì‹œì‘ ì§ì „ê¹Œì§€)
    video_durations = []
    for i in range(loop_count):
        start_t = aligned[i]["start"]
        
        if i < loop_count - 1:
            # ë‹¤ìŒ ë¼ì¸ ì‹œì‘ ì§ì „ê¹Œì§€ (ê°„ê²© ì—†ìŒ)
            next_start = aligned[i + 1]["start"]
            end_t = next_start
        else:
            # ë§ˆì§€ë§‰ ë¼ì¸ì€ ì˜¤ë””ì˜¤ ëê¹Œì§€
            end_t = audio_duration
        
        duration = end_t - start_t
        video_durations.append({
            "index": i,
            "start": start_t,
            "end": end_t,
            "duration": duration,
            "original_end": aligned[i]["end"]
        })
        
        gap_info = ""
        if i < loop_count - 1:
            gap = aligned[i + 1]["start"] - aligned[i]["end"]
            if gap > 0.1:
                gap_info = f" (+{gap:.2f}ì´ˆ ì—°ì¥)"
        
        print(f"   ë¼ì¸ [{i+1}]: {start_t:.2f}s ~ {end_t:.2f}s = {duration:.2f}ì´ˆ{gap_info}")
    
    # 2ë‹¨ê³„: ì˜ìƒ í´ë¦½ ìƒì„±
    for i in range(loop_count):
        line_info = aligned[i]
        text_line = line_info["text"]
        vd = video_durations[i]
        start_t = vd["start"]
        end_t = vd["end"]
        duration = vd["duration"]

        # ì˜ìƒ íŒŒì¼ 1:1 ë§¤í•‘ (ë¼ì¸ 1 -> 1.mp4, ë¼ì¸ 2 -> 2.mp4, ...)
        if i < len(VIDEO_FILES):
            video_path = VIDEO_FILES[i]
        else:
            # ì˜ìƒì´ ë¶€ì¡±í•œ ê²½ìš° ë§ˆì§€ë§‰ ì˜ìƒ ì¬ì‚¬ìš©
            video_path = VIDEO_FILES[-1]
            print(f"   âš ï¸ [{i+1}ë²ˆ ë¼ì¸] ì˜ìƒì´ ë¶€ì¡±í•˜ì—¬ {VIDEO_FILES[-1]}ì„(ë¥¼) ì¬ì‚¬ìš©í•©ë‹ˆë‹¤.")
        
        print(f"\n[{i+1}/{loop_count}] Scene ìƒì„± ì¤‘...")
        print(f"   ğŸ“ ëŒ€ì‚¬: {text_line}")
        print(f"   â± ì˜ìƒ ì‹œê°„: {duration:.2f}ì´ˆ ({start_t:.2f} ~ {end_t:.2f})")
        print(f"   ğŸ™ TTS ì‹œê°„: {vd['original_end'] - start_t:.2f}ì´ˆ ({start_t:.2f} ~ {vd['original_end']:.2f})")
        print(f"   ğŸ“¼ ì˜ìƒ: {video_path} (ë¼ì¸ {i+1} -> {video_path})")
        
        # ì˜ìƒ ê°€ê³µ (CapCut Style: Time Stretch) - ì—°ì¥ëœ duration ì‚¬ìš©
        video_clip = fit_video_to_audio(video_path, duration)
        final_clips.append(video_clip)
    
    # ì „ì²´ ì˜ìƒ ì—°ê²°
    print("\nğŸ  ì „ì²´ ì˜ìƒ ë Œë”ë§ ì¤€ë¹„ ì¤‘...")
    base_video = concatenate_videoclips(final_clips, method="compose")
    
    # ì „ì²´ íƒ€ì„ë¼ì¸ ê¸°ì¤€ìœ¼ë¡œ ìë§‰ ìƒì„±
    print("\nğŸ“ ìë§‰ ìƒì„± ì¤‘...")
    
    # 1ë‹¨ê³„: ëª¨ë“  chunk ì •ë³´ ìˆ˜ì§‘
    all_chunk_infos = []
    for i, line_info in enumerate(aligned):
        chunk_infos = chunk_words_with_times(line_info, MAX_LINE_CHARS)
        for chunk in chunk_infos:
            all_chunk_infos.append({
                "text": chunk["text"],
                "start": chunk["start"],
                "end": chunk["end"],
                "line_idx": i
            })
    
    # 2ë‹¨ê³„: ê° chunkì˜ end ì‹œê°„ì„ ë‹¤ìŒ chunk ì‹œì‘ ì§ì „ê¹Œì§€ ì—°ì¥ (ê°„ê²© 0ì´ˆ)
    for i in range(len(all_chunk_infos)):
        chunk = all_chunk_infos[i]
        
        if i < len(all_chunk_infos) - 1:
            # ë‹¤ìŒ chunkê°€ ìˆìœ¼ë©´ ê·¸ ì‹œì‘ ì§ì „ê¹Œì§€ ì—°ì¥ (ê°„ê²© ì—†ìŒ)
            next_chunk = all_chunk_infos[i + 1]
            chunk["end"] = next_chunk["start"]
        else:
            # ë§ˆì§€ë§‰ chunkëŠ” ì˜¤ë””ì˜¤ ëê¹Œì§€
            chunk["end"] = audio_duration
        
        # ìµœì†Œ duration ë³´ì¥ (0.4ì´ˆë¡œ ì™„í™”)
        min_duration = 0.4
        if chunk["end"] - chunk["start"] < min_duration:
            # ë‹¤ìŒ chunk ì‹œì‘ ì§ì „ê¹Œì§€ ì—°ì¥ (ë‹¨, ìµœì†Œ ì‹œê°„ ë³´ì¥)
            if i < len(all_chunk_infos) - 1:
                max_end = all_chunk_infos[i + 1]["start"]
                chunk["end"] = min(chunk["start"] + min_duration, max_end)
            else:
                chunk["end"] = min(chunk["start"] + min_duration, audio_duration)
    
    # 3ë‹¨ê³„: ìë§‰ ìƒì„± ë° ì¶œë ¥
    all_subtitles = []
    prev_line_idx = -1
    
    for i, chunk in enumerate(all_chunk_infos):
        chunk_start = chunk["start"]
        chunk_end = chunk["end"]
        chunk_duration = chunk_end - chunk_start
        
        # ë¼ì¸ êµ¬ë¶„ ì¶œë ¥
        if chunk["line_idx"] != prev_line_idx:
            print(f"\n   ë¼ì¸ [{chunk['line_idx']+1}]: {aligned[chunk['line_idx']]['text'][:40]}...")
            prev_line_idx = chunk["line_idx"]
        
        # ì´ìƒ ì²´í¬ ë° pause ì •ë³´
        info_items = []
        if chunk_duration < 0.4:
            info_items.append(f"âš ï¸ SHORT")
        if i > 0:
            gap = chunk_start - all_chunk_infos[i-1]["end"]
            if gap > 0.01:
                info_items.append(f"GAP:{gap:.2f}s")
            elif gap < -0.01:
                info_items.append(f"âš ï¸ OVERLAP")
        
        info_str = f" [{', '.join(info_items)}]" if info_items else ""
        
        sub = create_subtitle(chunk["text"], chunk_duration).set_start(chunk_start)
        all_subtitles.append(sub)
        print(f"      '{chunk['text']}' ({chunk_start:.2f}s ~ {chunk_end:.2f}s = {chunk_duration:.2f}s){info_str}")
    
    print(f"\nì´ {len(all_subtitles)}ê°œ ìë§‰ ìƒì„±ë¨")
    
    # ìë§‰ í•©ì„±
    final_video = CompositeVideoClip([base_video] + all_subtitles)
        
    # ì˜¤ë””ì˜¤ í•©ì„± (TTS + BGM)
    print("\nğŸµ ì˜¤ë””ì˜¤ í•©ì„± ì¤‘...")
    
    # BGM ì¶”ê°€ ì—¬ë¶€ í™•ì¸
    if BGM_PATH and os.path.exists(BGM_PATH):
        print(f"   âœ… ë°°ê²½ìŒì•…: {BGM_PATH}")
        print(f"   ğŸ”‰ BGM ë³¼ë¥¨: {BGM_VOLUME * 100:.0f}%")
        
        try:
            # BGM ë¡œë“œ
            bgm = AudioFileClip(BGM_PATH)
            
            # BGM ê¸¸ì´ë¥¼ ì˜ìƒ ê¸¸ì´ì— ë§ì¶¤
            if bgm.duration < audio_duration:
                # BGMì´ ì§§ìœ¼ë©´ ë£¨í”„
                num_loops = int(audio_duration / bgm.duration) + 1
                print(f"   ğŸ” BGM ë£¨í”„: {num_loops}íšŒ ë°˜ë³µ")
                bgm_clips = [bgm] * num_loops
                from moviepy.editor import concatenate_audioclips
                bgm = concatenate_audioclips(bgm_clips)
            
            # ì •í™•í•œ ê¸¸ì´ë¡œ ìë¥´ê¸°
            bgm = bgm.subclip(0, min(bgm.duration, audio_duration))
            
            # BGM ë³¼ë¥¨ ì¡°ì •
            bgm = bgm.volumex(BGM_VOLUME)
            
            # TTSì™€ BGM ë¯¹ì‹±
            final_audio = CompositeAudioClip([original_audio, bgm])
            final_video = final_video.set_audio(final_audio)
            print("   âœ… TTS + BGM ë¯¹ì‹± ì™„ë£Œ")
        except Exception as e:
            print(f"   âš ï¸ BGM ì¶”ê°€ ì‹¤íŒ¨: {e}")
            print("   â„¹ï¸ TTS ìŒì„±ë§Œ ì‚¬ìš©í•©ë‹ˆë‹¤")
            final_video = final_video.set_audio(original_audio)
    else:
        # BGM ì—†ìœ¼ë©´ TTSë§Œ ì‚¬ìš©
        print("   â„¹ï¸ ë°°ê²½ìŒì•… ì—†ìŒ")
        print("   â„¹ï¸ TTS ìŒì„±ë§Œ ì‚¬ìš©í•©ë‹ˆë‹¤")
        final_video = final_video.set_audio(original_audio)
    
    # ê¸¸ì´ ì •í™•íˆ ë§ì¶”ê¸°
    if final_video.duration > audio_duration:
        final_video = final_video.subclip(0, audio_duration)
    elif final_video.duration < audio_duration:
        print(f"   âš ï¸ ì˜ìƒ ê¸¸ì´({final_video.duration:.2f}s)ê°€ ì˜¤ë””ì˜¤({audio_duration:.2f}s)ë³´ë‹¤ ì§§ìŠµë‹ˆë‹¤.")
    
    # ë‚´ë³´ë‚´ê¸°
    print(f"\nğŸ’¾ ìµœì¢… ì˜ìƒ ê¸¸ì´: {final_video.duration:.2f}ì´ˆ (ì˜¤ë””ì˜¤: {audio_duration:.2f}ì´ˆ)")
    final_video.write_videofile("final_shorts_autofit.mp4", 
                                fps=30, 
                                codec="libx264", 
                                audio_codec="aac",
                                threads=4,
                                preset='medium')
    
    print("\nâœ¨ ì™„ì„±ë˜ì—ˆìŠµë‹ˆë‹¤! 'final_shorts_autofit.mp4' í™•ì¸")